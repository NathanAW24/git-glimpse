{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_huggingface import HuggingFaceEmbeddings  # Updated import for HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from transformers import pipeline\n",
    "from langchain_huggingface.llms import HuggingFacePipeline\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "if not torch.backends.mps.is_available():\n",
    "    raise EnvironmentError(\"MPS backend is not available. Ensure PyTorch is installed with MPS support.\")\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Argument to control whether to use the local database or re-index\n",
    "USE_LOCAL_DB = False  # Set to True to use existing local database, False to re-index\n",
    "\n",
    "# Directory paths\n",
    "PR_FOLDER = \"txt_processed_docs_githubv1\"  # Folder with PR data files\n",
    "VECTOR_DB_DIR = \"1_gte_small_githubv1\"  # Directory to save/load vector database\n",
    "\n",
    "MODEL_NAME = \"thenlper/gte-small\"\n",
    "\n",
    "# Step 1: Load PR Data\n",
    "def load_pr_data(pr_folder):\n",
    "    \"\"\"Load PR data from the specified folder.\"\"\"\n",
    "    pr_documents = []\n",
    "    for file in os.listdir(pr_folder):\n",
    "        if file.endswith(\".txt\"):\n",
    "            with open(os.path.join(pr_folder, file), 'r') as f:\n",
    "                content = f.read()\n",
    "                pr_documents.append(\n",
    "                    Document(\n",
    "                        page_content=content,\n",
    "                        metadata={\"file_name\": file}\n",
    "                    )\n",
    "                )\n",
    "    return pr_documents\n",
    "\n",
    "if not USE_LOCAL_DB:\n",
    "    print(\"Loading and processing PR data...\")\n",
    "    # Load PR data\n",
    "    pr_documents = load_pr_data(PR_FOLDER)\n",
    "\n",
    "    # Step 2: Create and store vector database\n",
    "    print(\"Generating embeddings and storing in vector database...\")\n",
    "    embedding_model = HuggingFaceEmbeddings(\n",
    "        model_name=MODEL_NAME,\n",
    "        model_kwargs={\"device\": \"mps\"},  # Adjust device as needed (e.g., \"cpu\", \"cuda\")\n",
    "        encode_kwargs={\"normalize_embeddings\": True}\n",
    "    )\n",
    "\n",
    "    # Create Chroma vector store\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=pr_documents,\n",
    "        embedding=embedding_model,\n",
    "        persist_directory=VECTOR_DB_DIR  # Save vector database locally\n",
    "    )\n",
    "\n",
    "    # Save the database for future use\n",
    "    vectorstore.persist()\n",
    "else:\n",
    "    print(\"Using existing local vector database...\")\n",
    "    # Load the existing vector database\n",
    "    embedding_model = HuggingFaceEmbeddings(\n",
    "        model_name=MODEL_NAME,\n",
    "        model_kwargs={\"device\": \"mps\"},  # Ensure the device matches the previous setup\n",
    "        encode_kwargs={\"normalize_embeddings\": True}\n",
    "    )\n",
    "    vectorstore = Chroma(\n",
    "        persist_directory=VECTOR_DB_DIR,\n",
    "        embedding_function=embedding_model\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Create a Retriever\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 10})\n",
    "\n",
    "# Step 5: Define RAG Prompt Template\n",
    "template = \"\"\"\n",
    "Use the following pieces of context to summarize the pull request. \n",
    "Always include the PR number, title, and any key changes or labels mentioned.\n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "rag_prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "result = retriever.invoke(\"\"\"Markdown Live Preview\n",
    "Reset\n",
    "Copy\n",
    "\n",
    "You can check your booking and cancel it through the [landing page] <URL to landing page>. Key in the Travel ID <paste kaligo booking ref> and the guest’s last name to access your booking.\n",
    "\n",
    "\n",
    "Location\n",
    "\n",
    "Location screenshot\n",
    "\n",
    "Copy\n",
    "\n",
    "Hotel details page, in the room selection\n",
    "\n",
    "Non-refundable\n",
    "\n",
    "Free cancellation (except a service fee) Before <Mon, 4 Nov>\n",
    "\n",
    "Cancellation fee applies\n",
    "\n",
    "Checkout page\n",
    "\n",
    "This booking is non-refundable\n",
    "\n",
    "This booking is non-refundable from 4 Nov 2024 12:00 AM onwards\n",
    "\n",
    "All times indicated are based on UTC time.\n",
    "\n",
    "Service fee of 5% of the refundable amount applies.\n",
    "\n",
    "There will be a cancellation fee of if you cancel the booking between Aug 14, 2017 12:00 AM and Aug 17, 2017 11:59 PM.\n",
    "\n",
    "All times indicated are based on UTC time.\n",
    "\n",
    "Service fee of 5% of the refundable amount applies.\n",
    "\n",
    "Instruction to cancel (below the policy):\n",
    "\n",
    "This is a pre-paid rate. To change the dates, number of rooms etc. you will need to cancel this reservation subject to the existing cancellation policy and make a new booking based on the prevailing rates and availability. You can check your booking and cancel it through the [landing page] . Key in the Travel ID and the guest’s last name to access your booking.\n",
    "\n",
    "Confirmation page\n",
    "\n",
    "Same cancelation policy as checkout page.\n",
    "\n",
    "Instruction to cancel (below the policy):\n",
    "\n",
    "This is a pre-paid rate. To change the dates, number of rooms etc. you will need to cancel this reservation subject to the existing cancellation policy and make a new booking based on the prevailing rates and availability. You can check your booking and cancel it through the [landing page] . Key in the Travel ID and the guest’s last name to access your booking.\n",
    "\n",
    "Confirmation email\n",
    "\n",
    "Same cancelation policy as checkout page.\n",
    "\n",
    "Instruction to cancel (below the policy):\n",
    "\n",
    "This is a pre-paid rate. To change the dates, number of rooms etc. you will need to cancel this reservation subject to the existing cancellation policy and make a new booking based on the prevailing rates and availability. You can check your booking and cancel it through the [landing page] . Key in the Travel ID and the guest’s last name to access your booking.\n",
    "\"\"\")\n",
    "\n",
    "# Print the entire result\n",
    "print(len(result))\n",
    "\n",
    "# Extract and print the pull request number and title for each document\n",
    "for doc in result:\n",
    "    content = doc.page_content\n",
    "    pr_number_match = re.search(r\"Pull Request Number: (\\d+)\", content)\n",
    "    title_match = re.search(r\"Title: (.+)\", content)\n",
    "    if pr_number_match and title_match:\n",
    "        pr_number = pr_number_match.group(1)\n",
    "        title = title_match.group(1)\n",
    "        print(f\"Pull Request Number: {pr_number}\")\n",
    "        print(f\"Title: {title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Load the LLM\n",
    "llm = HuggingFacePipeline(\n",
    "    pipeline=pipeline(\n",
    "        model=\"Qwen/Qwen2.5-0.5B-Instruct\",\n",
    "        task=\"text-generation\",\n",
    "        temperature=0.2,\n",
    "        do_sample=True,\n",
    "        repetition_penalty=1.1,\n",
    "        max_new_tokens=400,\n",
    "        device=device  # Use MPS backend\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Create the RAG Chain\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc[\"content\"] for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | rag_prompt\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Step 8: Example Query\n",
    "query = \"Summarize the most recent changes to checkout logic.\"\n",
    "print(\"Running query through RAG pipeline...\")\n",
    "result = retriever.invoke(query)\n",
    "# result = rag_chain.invoke({\"question\": query})\n",
    "print(\"Query Result:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
